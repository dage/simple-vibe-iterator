# integration-tests/test_multi_output.py
from __future__ import annotations

import asyncio
from pathlib import Path
from typing import List, Tuple, Dict
import os
import sys


def get_project_root() -> Path:
    return Path(__file__).resolve().parents[1]


def ensure_cwd_project_root() -> Path:
    root = get_project_root()
    os.chdir(root)
    return root


def inject_src_into_syspath(project_root: Path) -> None:
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))


# Test stub services that differentiate output by model
class _TestMultiOutputAICodeService:
    async def generate_html(self, prompt: str, model: str) -> str:
        await asyncio.sleep(0.05)
        safe_prompt = (prompt or "").strip()[:100]
        model_marker = f"Model: {model}"
        return (
            "<!DOCTYPE html>\n"
            "<html><head><meta charset=\"utf-8\"><title>Generated by AI</title>\n"
            "<style>body{font-family:sans-serif;padding:24px} .model{background:#f0f0f0;padding:8px;margin:8px}</style>\n"
            "</head><body>\n"
            f"<h1>Generated Content</h1>\n"
            f"<div class=\"model\">{model_marker}</div>\n"
            f"<div><pre>{safe_prompt[:100]}</pre></div>\n"
            "<script>console.log('Multi-output test page loaded');</script>\n"
            "</body></html>"
        )


class _TestMultiOutputVisionService:
    async def analyze_screenshot(self, prompt: str, screenshot_path: str, console_logs: List[str], model: str) -> str:
        await asyncio.sleep(0.01)
        name = Path(screenshot_path).name
        lines = [
            f"Vision analysis by {model}",
            f"Screenshot: {name}",
            f"Console entries: {len(console_logs)}",
            f"Prompt length: {len((prompt or '').encode('utf-8'))}",
        ]
        return "\n".join(lines)


async def build_multi_output_controller():
    from src.services import PlaywrightBrowserService
    from src.controller import IterationController

    ai = _TestMultiOutputAICodeService()
    browser = PlaywrightBrowserService()
    vision = _TestMultiOutputVisionService()
    return IterationController(ai, browser, vision)


def default_settings(overall_goal: str = "", code_model: str = "test-model"):
    from src.interfaces import TransitionSettings

    return TransitionSettings(
        code_model=code_model,
        vision_model="test-vision-model",
        overall_goal=overall_goal,
        user_steering="",
        code_template=(
            "Generate HTML for the goal.\n"
            "Goal: {overall_goal}\n"
            "Vision analysis: {vision_output}\n"
            "User steering: {user_steering}\n"
            "HTML input: {html_input}\n"
        ),
        vision_template=(
            "Analyze screenshot.\n"
            "Goal: {overall_goal}\n"
            "User steering: {user_steering}\n"
            "HTML: {html_input}\n"
        ),
    )


async def test_single_model_backward_compatibility() -> Tuple[bool, str]:
    """Test that single model still works as before"""
    ctrl = await build_multi_output_controller()
    settings = default_settings("Single model test", "single-model")
    node_id = await ctrl.apply_transition(None, settings)
    
    node = ctrl.get_node(node_id)
    if not node:
        return False, "Node not created"
        
    # Should have exactly one output entry
    if len(node.outputs) != 1:
        return False, f"Expected 1 output, got {len(node.outputs)}"
        
    # The key should be the model name
    if "single-model" not in node.outputs:
        return False, f"Model key missing, got keys: {list(node.outputs.keys())}"
        
    output = node.outputs["single-model"]
    if not output.html_output.strip():
        return False, "Empty html_output"
        
    if "single-model" not in output.html_output:
        return False, "Model marker not in html_output"
        
    if not output.artifacts.screenshot_filename:
        return False, "Missing screenshot_filename"
        
    return True, "Single model backward compatibility OK"


async def test_multiple_models() -> Tuple[bool, str]:
    """Test comma-separated models produce multiple outputs"""
    ctrl = await build_multi_output_controller()
    settings = default_settings("Multi model test", "model-a,model-b,model-c")
    node_id = await ctrl.apply_transition(None, settings)
    
    node = ctrl.get_node(node_id)
    if not node:
        return False, "Node not created"
        
    # Should have exactly three output entries
    if len(node.outputs) != 3:
        return False, f"Expected 3 outputs, got {len(node.outputs)}"
        
    expected_models = ["model-a", "model-b", "model-c"]
    for model in expected_models:
        if model not in node.outputs:
            return False, f"Model {model} missing from outputs"
            
        output = node.outputs[model]
        if not output.html_output.strip():
            return False, f"Empty html_output for {model}"
            
        if f"Model: {model}" not in output.html_output:
            return False, f"Model marker not found in {model} output"
            
        if not output.artifacts.screenshot_filename:
            return False, f"Missing screenshot for {model}"
            
        # Each model should have its own artifacts
        screenshot_path = Path(output.artifacts.screenshot_filename)
        if not screenshot_path.exists():
            return False, f"Screenshot file doesn't exist for {model}: {screenshot_path}"
            
    return True, "Multiple models OK"


async def test_iterate_from_multi_output() -> Tuple[bool, str]:
    """Test iterating from one output of a multi-output node"""
    ctrl = await build_multi_output_controller()
    
    # Create parent with multiple outputs
    parent_settings = default_settings("Parent goal", "model-1,model-2")
    parent_id = await ctrl.apply_transition(None, parent_settings)
    
    parent_node = ctrl.get_node(parent_id)
    if not parent_node or len(parent_node.outputs) != 2:
        return False, "Parent multi-output setup failed"
        
    # Iterate from model-2's output specifically
    child_settings = default_settings("Child goal", "model-2")
    child_id = await ctrl.apply_transition(parent_id, child_settings)
    
    child_node = ctrl.get_node(child_id)
    if not child_node:
        return False, "Child node not created"
        
    # Child should have single output
    if len(child_node.outputs) != 1:
        return False, f"Child should have 1 output, got {len(child_node.outputs)}"
        
    if "model-2" not in child_node.outputs:
        return False, "Child model key missing"
        
    # The html_input to the child should come from model-2's output
    # This verifies that the controller correctly used the specified model's HTML
    expected_input = parent_node.outputs["model-2"].html_output
    if child_node.html_input != expected_input:
        return False, "Child html_input doesn't match model-2's output"
        
    return True, "Iterate from multi-output OK"


async def test_model_whitespace_handling() -> Tuple[bool, str]:
    """Test that whitespace in comma-separated models is handled correctly"""
    ctrl = await build_multi_output_controller()
    settings = default_settings("Whitespace test", " model-x , model-y , model-z ")
    node_id = await ctrl.apply_transition(None, settings)
    
    node = ctrl.get_node(node_id)
    if not node:
        return False, "Node not created"
        
    # Should have exactly three outputs with trimmed model names
    expected_models = ["model-x", "model-y", "model-z"]
    if len(node.outputs) != 3:
        return False, f"Expected 3 outputs, got {len(node.outputs)}"
        
    for model in expected_models:
        if model not in node.outputs:
            return False, f"Trimmed model {model} missing from outputs"
            
    return True, "Whitespace handling OK"


async def test_empty_model_handling() -> Tuple[bool, str]:
    """Test that empty models in comma-separated list are filtered out"""
    ctrl = await build_multi_output_controller()
    settings = default_settings("Empty model test", "model-1,,model-2,")
    node_id = await ctrl.apply_transition(None, settings)
    
    node = ctrl.get_node(node_id)
    if not node:
        return False, "Node not created"
        
    # Should have exactly two outputs (empty strings filtered out)
    expected_models = ["model-1", "model-2"]
    if len(node.outputs) != 2:
        return False, f"Expected 2 outputs (empty filtered), got {len(node.outputs)}"
        
    for model in expected_models:
        if model not in node.outputs:
            return False, f"Model {model} missing from outputs"
            
    return True, "Empty model filtering OK"


async def main() -> int:
    project_root = ensure_cwd_project_root()
    inject_src_into_syspath(project_root)

    checks = [
        ("Single Model Backward Compatibility", test_single_model_backward_compatibility),
        ("Multiple Models", test_multiple_models),
        ("Iterate from Multi-Output", test_iterate_from_multi_output),
        ("Model Whitespace Handling", test_model_whitespace_handling),
        ("Empty Model Handling", test_empty_model_handling),
    ]

    ok_all = True
    for name, fn in checks:
        try:
            ok, msg = await fn()
        except Exception as exc:
            ok, msg = False, f"error: {exc}"
        status = "OK" if ok else "FAIL"
        print(f"[ {status} ] {name}: {msg}")
        ok_all = ok_all and ok

    return 0 if ok_all else 1


if __name__ == "__main__":
    raise SystemExit(asyncio.run(main()))